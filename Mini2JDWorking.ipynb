{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Models: Logistic Regression\n",
    "\n",
    "To recap from project 1, we are using the 'flights' data set, as found on Kaggle. Our main interest is predicting the arrival delay of flights. In this round of analysis, we are interested in predicting arrival delays exceeding fifteent minutes. We hypothesize we will take our classification efforts further in the next project to arrive at an ordinal prediction. For now, we are focused on the variable ARRIVAL_IND, which represents the arrival indicator of 0=not delayed at arrival and 1=delayed at arrival.\n",
    "\n",
    "Project 1's exploratory data analysis led us to believe that delays vary by region and airline. Instead of modeling all U.S. flights, we will focus our efforts on predicting flights leaving Atlanta's Hartsfield-Jackson Airport. We chose this airport for analysis because it is the busiest in the country. In addition to subsetting by the busiest airport, we aim to articulate this modeling effort to likely business/operations metrics.\n",
    "\n",
    "Our first effort will be to create logistic regression models. While we strive for an accurate model, we also seek to develop a sparse model of comparable accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data import and cleaning\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('rawdata.csv',low_memory=False, encoding = 'ISO-8859-1')\n",
    "df1 = df1.drop(['ARRIVAL_DELAY', 'DEPARTURE_IND', 'DEPARTURE_DELAY', 'ARRIVAL_DELAY', 'CANCELLATION_REASON', 'YEAR',\n",
    "                'Unnamed: 0','DATE', 'AIRLINE', 'DESTINATION_LONGITUDE', 'DESTINATION_LATITUDE', 'DESTINATION_AIRPORT_NAME',\n",
    "                'DEPARTING_LONGITUDE','DEPARTING_LATITUDE','DEPARTING_AIRPORT_ NAME', 'CANCELLED', 'DIVERTED', 'TAIL_NUMBER',\n",
    "                'FLIGHT_NUMBER','DEPARTING_CITY','DEPARTING_STATE', 'DEPARTING_COUNTRY', 'DEPARTING_REGION'],\n",
    "               axis=1)\n",
    "\n",
    "column_titles = ['MONTH', 'DAY','DAY_OF_WEEK', 'AIRLINE_CODE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'DESTINATION_CITY', \n",
    "                 'DESTINATION_STATE', 'DESTINATION_COUNTRY','DESTINATION_REGION', 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME',\n",
    "                'TAXI_OUT', 'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME','AIR_TIME', 'DISTANCE', 'WHEELS_ON','TAXI_IN', \n",
    "                'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME','SECURITY_DELAY', 'AIRLINE_DELAY','LATE_AIRCRAFT_DELAY',\n",
    "                'WEATHER_DELAY','ARRIVAL_IND']\n",
    "\n",
    "#reorder the columns\n",
    "df1 = df1.reindex(columns=column_titles)\n",
    "\n",
    "#focus on world's busiest airport in this analysis\n",
    "ATL1 = df1.loc[df1['ORIGIN_AIRPORT'] == 'ATL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 61460 entries, 38 to 931955\n",
      "Data columns (total 27 columns):\n",
      "MONTH                  61460 non-null int64\n",
      "DAY                    61460 non-null int64\n",
      "DAY_OF_WEEK            61460 non-null int64\n",
      "AIRLINE_CODE           61460 non-null object\n",
      "ORIGIN_AIRPORT         61460 non-null object\n",
      "DESTINATION_AIRPORT    61460 non-null object\n",
      "DESTINATION_CITY       61460 non-null object\n",
      "DESTINATION_STATE      61460 non-null object\n",
      "DESTINATION_COUNTRY    61460 non-null object\n",
      "DESTINATION_REGION     61460 non-null object\n",
      "SCHEDULED_DEPARTURE    61460 non-null int64\n",
      "DEPARTURE_TIME         61460 non-null float64\n",
      "TAXI_OUT               61460 non-null float64\n",
      "WHEELS_OFF             61460 non-null float64\n",
      "SCHEDULED_TIME         61460 non-null float64\n",
      "ELAPSED_TIME           61460 non-null float64\n",
      "AIR_TIME               61460 non-null float64\n",
      "DISTANCE               61460 non-null int64\n",
      "WHEELS_ON              61460 non-null float64\n",
      "TAXI_IN                61460 non-null float64\n",
      "SCHEDULED_ARRIVAL      61460 non-null int64\n",
      "ARRIVAL_TIME           61460 non-null float64\n",
      "SECURITY_DELAY         61460 non-null float64\n",
      "AIRLINE_DELAY          61460 non-null float64\n",
      "LATE_AIRCRAFT_DELAY    61460 non-null float64\n",
      "WEATHER_DELAY          61460 non-null float64\n",
      "ARRIVAL_IND            61460 non-null float64\n",
      "dtypes: float64(14), int64(6), object(7)\n",
      "memory usage: 13.1+ MB\n"
     ]
    }
   ],
   "source": [
    "ATL1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    52063\n",
       "1.0     9397\n",
       "Name: ARRIVAL_IND, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATL1['ARRIVAL_IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One hot encode using a temporary data frame\n",
    "ATL1 = pd.get_dummies(ATL1, prefix=['AIRLINE_CODE', 'DESTINATION_AIRPORT','DESTINATION_CITY', 'DESTINATION_STATE',\n",
    "                                     'DESTINATION_COUNTRY', 'DESTINATION_REGION'],\n",
    "                       columns=['AIRLINE_CODE', 'DESTINATION_AIRPORT', 'DESTINATION_CITY', 'DESTINATION_STATE',\n",
    "                                     'DESTINATION_COUNTRY', 'DESTINATION_REGION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove redundant predictors\n",
    "\n",
    "if 'ORIGIN_AIRPORT' in ATL1:\n",
    "    del ATL1['ORIGIN_AIRPORT']\n",
    "\n",
    "if 'AIRLINE_CODE' in ATL1:\n",
    "    del ATL1['AIRLINE_CODE']\n",
    "    \n",
    "if 'DESTINATION_AIRPORT' in ATL1:    \n",
    "    del ATL1['DESTINATION_AIRPORT']\n",
    "    \n",
    "if 'DESTINATION_CITY' in ATL1:    \n",
    "    del ATL1['DESTINATION_CITY']\n",
    "\n",
    "if 'DESTINATION_STATE' in ATL1:    \n",
    "    del ATL1['DESTINATION_STATE']\n",
    "    \n",
    "if 'DESTINATION_COUNTRY' in ATL1:    \n",
    "    del ATL1['DESTINATION_COUNTRY']\n",
    "    \n",
    "if 'DESTINATION_REGION' in ATL1:    \n",
    "    del ATL1['DESTINATION_REGION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of the data frame after adding dummy variables is (61460, 395)\n"
     ]
    }
   ],
   "source": [
    "#create X and y variables for modeling\n",
    "X = ATL1.drop('ARRIVAL_IND', axis = 1).values\n",
    "y = ATL1['ARRIVAL_IND'].values\n",
    "print(\"The Shape of the data frame after adding dummy variables is\", ATL1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will need to go through some basic data cleaning. We will read in the data output from project 1 and remove variables that are intuitively of no use to our modeling. Next, we rearrange our columns to a sequence that follows all discrete variables, followed by continuous features. Because our data set is rich in categorical features, mostly geographic, we must create dummy variables (one hot encoding) for this data set. As a final step, we define our X and y variables, where y is equal to ARRIVAL_IND and X is equal to all other features.\n",
    "\n",
    "Once we account for our newly created dummy varibles, our data set grows to 399 features. Before we begin to construst a robust model, we must first perform variable selection.\n",
    "\n",
    "We will also make sure all the variables are on the same scale to ensure we don't improperly weight any variables that may be on a different scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create an object to scale data using standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "#scale X to make zero mean and unit standard deviation\n",
    "scl_obj.fit(X) \n",
    "X_scaled = scl_obj.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import feature selection and logistic regression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we want to maximize accuracy and precision, we also want to find a sparse model. A model with the least coefficients and generalizes well to the test data is our goal. To do so, we will make use of our entire data set to explore feature importance. We will not use any of the found coefficient in our model; this step is simply to reduce the dimensionality of our data set. We will control our variable selection method by using L1 regularization: \"The main concept behind L1 regularization is...the L1 penalty is the sum of the absolute weight coefficients...(and) serves as a method for feature selection\"(Python Machine Learning 2nd ed, Sebastian Raschka, pg. 126-128).\n",
    "\n",
    "We set 'C' parameter low to encourage a sparse solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61460, 392)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a model to use as input to select from model\n",
    "logreg = LogisticRegression(C=10, penalty=\"l1\", dual=False).fit(X,y)\n",
    "model = SelectFromModel(logreg, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
       "       249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
       "       262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
       "       275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287,\n",
       "       288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300,\n",
       "       301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313,\n",
       "       314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326,\n",
       "       327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
       "       340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352,\n",
       "       353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
       "       366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
       "       379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
       "       392, 393], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out the features that were not zeroed out from the L1 regularization.\n",
    "#These will be the features to use in the sparse data set. \n",
    "model.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a new data frame of the selected variables\n",
    "ATL_trimmed = ATL1.ix[:,[0,   1,   2,   3,  4,  5,   6,   7,   8,   9,  10,  11,  12,\n",
    "        13,  14,  15,  16,  17,  18,  21, 386, 387, 391]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at our variables left after L1 regularization.\n",
    "ATL_trimmed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see from the selected variables is not surprising: destination plays a large role and region is favored over the individual destination city variables. Also, we see that all of our delay variables are included. As we strive to translate this model to operational/business metrics, we want to pay close attention to the delay variable(s) with the largest coefficents, as they will help guide our final message. Time of departure is also a relevant feature. We will discuss more variable interpretation in the \"Interpret Feature Importance\" section.\n",
    "\n",
    "Now that we have a smaller subset of features, we will begin the logistic model development and improvement. We begin with a model that doesn't make use of Grid Search. We will address model performance and then proceed to improve the model by improving model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trimmed = ATL_trimmed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a train/test split of 80% of instances allocated for training and 20% allocated for test\n",
    "#random state set for reproducibility\n",
    "logreg = LogisticRegression()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_trimmed,y,test_size=0.2, random_state = 42)\n",
    "\n",
    "#scale our X values\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) \n",
    "\n",
    "# find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test)\n",
    "\n",
    "#fit model\n",
    "logreg.fit(X_train_scaled,y_train)\n",
    "\n",
    "#Predict on test data set\n",
    "yhat = logreg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking to see if test was roughly same amount of imbalance. \n",
    "import numpy\n",
    "np = y_test.astype(int)\n",
    "numpy.bincount(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort these attributes and print out model coefficients\n",
    "zip_vars = zip(logreg.coef_.T, ATL_trimmed) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the coefficients\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "weights = pd.Series(logreg.coef_[0],index=ATL_trimmed.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from our initial model that accuracy is already high. Let's take a closer look at some of the performance metrics of this model before we utilize grid search to improve the model, as well as our variables skewed heavily towards the delay indicators. We will proceed with evaluating model performance and then move towards improving results with GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "conf = mt.confusion_matrix(y_test,yhat)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both metrics, confusion matrix and classification report, show us that this is a high performing model. Recall is defined as\n",
    "R = \\frac{T_p}{T_p + F_n}.\n",
    "\n",
    "We are interested in this metric in particular because we want to minimize our false negative rate because it is the most meaningful metric for this type of problem. ~~A flight predicted as not arriving late when it actually is late, is considered \"high cost\" for this problem as we strive to make this a relevant operational metric because we aim to make this classification task actionable for the end user.~~ For the users of our algorithm, it's most important to minimize the number of flights we say are on time, but are late in reality. How many flights are actually late vs how many we predict to be late is our most valuable metric. Here we are able to predict with a very high degree of accuracy.\n",
    "\n",
    "\n",
    "We finally see the trade off curve plotted below. Our results allow us to achieve both high precision and recall, a rare finding in an imbalanced data set. The imbalance of the data set is about 15% or to put it another way we could predict every flight to be on time and have an 85% accuracy rate. Our model improves on that substantially, with both training and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, yhat)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "precision, recall, _ = precision_recall_curve(y_test, yhat)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall Curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "plt.show()\n",
    "\n",
    "#source: scikitlearn documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, we performed variable selection and created a model based on the terms that were not penalized to 0 coefficients in L1 regularization. We saw that the model performed well based on an 80/20 train/test split. We will now investigate how to improve upon an already strong model using GridSearchCV. The variable we want to improve is C:\"Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization\" (scikit learn logistic regression documentation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set up parameter grid search for C variable\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "logreg = LogisticRegression()\n",
    "clf = GridSearchCV(logreg, param_grid)\n",
    "\n",
    "#fit model\n",
    "clf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the best paramter of C found and best score\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found the optimal parameter of C to be 1000. It is not computationally efficient to find the true optimum of C. However, give the score increase, we conclude this model is optimized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print test accuracy using best estimator from gridsearch\n",
    "grid_model = clf.best_estimator_\n",
    "grid_model.fit(X_train_scaled, y_train)\n",
    "grid_test = grid_model.predict(X_test_scaled)\n",
    "print('Test accuracy: %.3f' % grid_model.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate performance via confusion matrix\n",
    "conf = mt.confusion_matrix(y_test,grid_test)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the classification report\n",
    "print(classification_report(y_test,grid_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we have imporved our the model performance, as both recall and F1-score have improved for our positive class of ARRIVAL DELAY = 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort these attributes and print out model coefficients\n",
    "zip_vars = zip(grid_model.coef_.T, ATL_trimmed) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the coefficients\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "weights = pd.Series(grid_model.coef_[0],index=ATL_trimmed.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret Feature Imortance\n",
    "We see that our model assigns the highest importance to the delay variables. Late Aircraft delay, airline dleay, and weather delay are our top three predictors of a significant late arrival when the origin airport is Atlanta. These coefficients are positive, meaning as these delays increase, so does the probability of one arriving late to his/her destination. \n",
    "\n",
    "##Joe--need help her for interpretation. \n",
    "\n",
    "In regards to why the variables are so important: let's phrase this in the context of us trying to implement an operational metric with the goal of presenting to airport operations and developing metrics rather than delays at destination cause late arrivals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Models: Support Vector Machine\n",
    "\n",
    "We will now transition to modeling our data using a support vector machine classifier. We have a high benchmark to hit in terms of accuracy. However, we are also interested in evaluating the other pros and cons of each model, discussed in model advantages. For example, if we can achieve a more sparse model with comparable accuracy utilizing SVM, we will likely tend to pick that method, as it is assumed our audience will prefer a simple solution. \n",
    "\n",
    "Just as with logistic regression, we begin with variable selection in order to reduce our massive data set to a more manageable size. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT ADDITIONAL MODULES FOR SVC AND GRAPHICS\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Shape of the data frame after adding dummy variables is\", ATL1.shape)\n",
    "#create an object to scale data using standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scl_obj = StandardScaler()\n",
    "\n",
    "#scale X to make zero mean and unit standard deviation\n",
    "scl_obj.fit(X) \n",
    "X_scaled = scl_obj.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin variable selection\n",
    "SVC_1 = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X,y)\n",
    "Model_1 = SelectFromModel(SVC_1, prefit=True)\n",
    "X_new_1 = Model_1.transform(X)\n",
    "X_new_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that SVC picked approximately the same attributes for modeling. We continue with building our initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the features that were not zeroed out from the L1 regularization.\n",
    "#These will be the features to use in the sparse data set. \n",
    "Model_1.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a new data frame of the selected 25 variables\n",
    "ATL_trimmed = ATL1.ix[:,[0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
    "        13,  14,  15,  16,  17,  18,  22,  25, 287, 387, 391, 392]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATL_trimmed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed the differences between the variables selected for Logistic Regression compared to SVC. For example, Airline code, destination airport, destination state, and destination region are all different. \n",
    "\n",
    "What we see from the selected variables is not surprising: destination plays a large role and region is favored over the individual destination city variables. Also, we see that all of our delay variables are included, just as we saw in the logistic regression models. As we strive to translate this model to operational/business metrics, we want to pay close attention to the delay variable(s) with the largest coefficents, as they will help guide our final message. Time of departure is also a relevant feature. We will discuss more variable interpretation in the \"Interpret Support Vectors\" section.\n",
    "Now that we have a smaller subset of features, we will begin the SVC development and improvement. We begin with a model that doesn't make use of Grid Search. We will address model performance and then proceed to improve the model by improving model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X values assigned\n",
    "X_trimmed_svc = ATL_trimmed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign a train/test split of 80/20, 80% allocated for training, 20% allocated for test. \n",
    "X_train_svc,X_test_svc,y_train_svc,y_test_svc = train_test_split(X_trimmed_svc,y,test_size=0.2, random_state = 42)\n",
    "\n",
    "#create instace of SVC\n",
    "SVC = LinearSVC()\n",
    "\n",
    "#scale our X values\n",
    "#scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train_svc) \n",
    "\n",
    "# find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "X_train_scaled_svc = scl_obj.transform(X_train_svc) # apply to training\n",
    "X_test_scaled_svc = scl_obj.transform(X_test_svc)\n",
    "\n",
    "#fit model\n",
    "SVC.fit(X_train_scaled_svc,y_train_svc)\n",
    "\n",
    "#Predict on test data set\n",
    "y_hat_svc = SVC.predict(X_test_scaled_svc)\n",
    "\n",
    "print (\"Score:\", SVC.score(X_test_scaled_svc, y_test_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort these attributes and print out model coefficients\n",
    "zip_vars = zip(SVC.coef_.T, ATL_trimmed) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the coefficients\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "weights = pd.Series(SVC.coef_[0],index=ATL_trimmed.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our SVM modeling follows the same train/test split pattern as see in the logistic regression section. Because our features are on different scales, we also use the standard scaler function. The model is trained on 80% of the instances and tested on 20% of the instances. Our first indication of model performance is seen above using the SVC.score function. We see nearly equivalent performance as we saw on the first pass of logistic regression. \n",
    "\n",
    "Let's now take an even closer look at the various classification metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "conf_svc1 = mt.confusion_matrix(y_test_svc,y_hat_svc)\n",
    "conf_svc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_svc,y_hat_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test_svc, y_hat_svc)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "precision, recall, _ = precision_recall_curve(y_test_svc, y_hat_svc)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall Curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "plt.show()\n",
    "\n",
    "#source: scikitlearn documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see above in the confusion matrix and classification report is exceptional performance. Our minority class, delays, are predicted well. To truly outperform logistic regression, we need to see better recall in the 1 class (arrival delays). Additionally, the precision-recall curve indicates strong precision/recall tradeoff without much of a sacrifice in the performance of either class. \n",
    "\n",
    "Before moving on to an optimized model, we will plot this model's coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM model's coefficients, much like the past models reinforce that the delays at the origin airport, ATL, have strong predictive power on the probability of a delayed arrival. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, we performed variable selection and created a SVC model based on the terms that were not penalized to 0 coefficients in L1 regularization. We saw that the model performed well based on an 80/20 train/test split. We will now investigate how to improve upon an already strong model using GridSearchCV. The variable we want to improve is C:\"Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization\" (scikit learn logistic regression documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up parameter grid search for C variable\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "SVC = SVC = LinearSVC()\n",
    "clf_svc = GridSearchCV(SVC, param_grid)\n",
    "\n",
    "#fit model\n",
    "clf_svc.fit(X_train_scaled_svc,y_train_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the best paramter of C found and best score\n",
    "print(clf_svc.best_score_)\n",
    "print(clf_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print test accuracy using best estimator from gridsearch\n",
    "grid_model_svc = clf_svc.best_estimator_\n",
    "grid_model_svc.fit(X_train_scaled_svc, y_train_svc)\n",
    "gridpredict = grid_model_svc.predict(X_test_scaled_svc)\n",
    "print('Test accuracy: %.3f' % grid_model_svc.score(X_test_scaled_svc, y_test_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate performance via confusion matrix\n",
    "conf_gridsvm = mt.confusion_matrix(y_test_svc,gridpredict)\n",
    "conf_gridsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the classification report\n",
    "print(classification_report(y_test_svc,yhatgridsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort these attributes and print out model coefficients\n",
    "zip_vars = zip(grid_model_svc.coef_.T, ATL_trimmed) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the coefficients\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "weights = pd.Series(grid_model_svc.coef_[0],index=ATL_trimmed.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vectors\n",
    "print(SVC.support_vectors_.shape)\n",
    "#print(svm_clf.support_.shape)\n",
    "#print(svm_clf.n_support_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
